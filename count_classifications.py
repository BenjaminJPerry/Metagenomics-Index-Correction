#!/usr/bin/env python3
"""
This script parses a Centrifuge-generated SAM file to give some stats about the classifications.

It prints a single-row table to stdout that summarises the SAM file with the following columns:
  * file:                 the name of the SAM file
  * read_count:           the total number of reads
  * unclassified_count:   the number of reads which were not classified
  * unclassified_percent: the percentage of reads which were not classified
  * root_count:           the number of reads with an LCA classification to the root level
  * root_percent:         the percentage of reads with an LCA classification to the root level
  * domain_count:         the number of reads with an LCA classification to the domain level
  * domain_percent:       the percentage of reads with an LCA classification to the domain level
  * phylum_count:         the number of reads with an LCA classification to the phylum level
  * phylum_percent:       the percentage of reads with an LCA classification to the phylum level
  * class_count:          the number of reads with an LCA classification to the class level
  * class_percent:        the percentage of reads with an LCA classification to the class level
  * order_count:          the number of reads with an LCA classification to the order level
  * order_percent:        the percentage of reads with an LCA classification to the order level
  * family_count:         the number of reads with an LCA classification to the family level
  * family_percent:       the percentage of reads with an LCA classification to the family level
  * genus_count:          the number of reads with an LCA classification to the genus level
  * genus_percent:        the percentage of reads with an LCA classification to the genus level
  * species_count:        the number of reads with an LCA classification to the species level
  * species_percent:      the percentage of reads with an LCA classification to the species level
  * lca_ids:              the number of distinct LCA (one per read) classifications
  * align_ids:            the number of distinct per-alignment (can be multiple per read)
                          classifications
  * leaf_ids:             the number of distinct per-alignment classifications to leaf nodes of the
                          taxonomy tree
  * total_ids:            the number of distinct classifications of any type (either per-alignment
                          or LCA)

It also prints a one-row-per-read table to stderr with the following columns:
  * read_name:            the read name
  * alignment_classes:    a comma-delimited list of per-alignment tax IDs for the read, can have
                          one or multiple values
  * lca_class:            the tax ID for the LCA of the per-alignment tax IDs, always has one value
  * lca_rank:             the taxonomic rank of the classification (unclassified, root, domain,
                          phylum, class, order, family, genus or species)
"""

import argparse
import collections
import gzip
import sys


def get_arguments():
    parser = argparse.ArgumentParser(description='Summarise classifications from Centrifuge SAM '
                                                 'files')
    parser.add_argument('--sam', type=str,
                        help='a SAM file generated by Centrifuge (can be gzipped)')
    parser.add_argument('--tree', type=str,
                        help='a taxonomy tree file (can be gzipped)')
    parser.add_argument('--header', action='store_true',
                        help='include a header row in the output')
    args = parser.parse_args()
    check_arguments(args)
    return args


def main():
    args = get_arguments()
    print_headers(args)

    tax_id_to_parent, tax_id_to_rank, leaf_ids = load_tax_info(args.tree)
    tax_ids_per_read = load_tax_ids_per_read(args.sam)
    read_count = len(tax_ids_per_read)

    count_per_rank = collections.defaultdict(int)
    align_ids, leaves, lca_ids = set(), set(), set()
    for read_name, tax_ids in tax_ids_per_read.items():
        lca_id = add_rank_count(read_name, count_per_rank, tax_ids, tax_id_to_rank, tax_id_to_parent)
        align_ids.update(tax_ids)
        leaves.update(i for i in tax_ids if i in leaf_ids)
        lca_ids.add(lca_id)

    print_summary(args.sam, read_count, count_per_rank, align_ids, leaves, lca_ids)


def load_tax_info(tree_filename):
    """
    This function reads through the tree file, and returns two dictionaries:
      1) Where the keys are tax IDs and the values are the parent tax IDs. This dictionary allows
         for tracing 'upward' (toward the root) through the tree, starting at any node.
      2) Where the keys are tax IDs and the values are taxonomic ranks. Importantly, this
         dictionary does not include all taxonomic ranks in the tree, but only the standard levels
         (phylum, class, order, etc). When a tax ID has a non-standard rank (e.g. subfamily), that
         ID is given the first standard rank found in its ancestors (e.g. family).
    """
    tree_data = []
    open_func = get_open_func(tree_filename)
    with open_func(tree_filename, 'rt') as tree_file:
        for line in tree_file:
            parts = line.strip().split('\t')
            tree_data.append([int(parts[0]), int(parts[2]), parts[4].lower()])

    tax_id_to_parent = {}
    for tax_id, parent_id, _ in tree_data:
        tax_id_to_parent[tax_id] = parent_id

    # The first time we go through the tax IDs, we save any which has an acceptable rank.
    tax_id_to_rank = {0: 'unclassified'}
    acceptable_ranks = {'domain', 'phylum', 'class', 'order', 'family', 'genus', 'species'}
    for tax_id, parent_id, rank in tree_data:
        if rank in acceptable_ranks:
            tax_id_to_rank[tax_id] = rank
        elif tax_id == 1:  # special case for the root node
            assert tax_id == parent_id  # the root is its own parent
            tax_id_to_rank[tax_id] = 'root'

    # Now we go through a second time to deal with tax IDs that didn't get an acceptable rank the
    # first time.
    for tax_id, _, rank in tree_data:
        if tax_id in tax_id_to_rank:
            continue
        assert rank not in acceptable_ranks
        ancestors = get_all_ancestors(tax_id, tax_id_to_parent)
        for ancestor in ancestors:
            if ancestor in tax_id_to_rank:
                rank = tax_id_to_rank[ancestor]
                tax_id_to_rank[tax_id] = rank
                break
        assert tax_id in tax_id_to_rank

    all_tax_ids = set(tax_id_to_parent.keys())
    leaf_ids = all_tax_ids - set(tax_id_to_parent.values())

    return tax_id_to_parent, tax_id_to_rank, leaf_ids


def load_tax_ids_per_read(sam_filename):
    """
    Returns a dictionary where the key is the read name and the value is a list of all tax IDs that
    read was classified to.
    """
    tax_ids_per_read = collections.OrderedDict()
    with get_open_func(sam_filename)(sam_filename, 'rt') as sam_file:
        for line in sam_file:
            parts = line.strip().split('\t')
            read_name = parts[0]
            if read_name == 'readID':  # header
                continue
            tax_id = int(parts[2])
            if read_name not in tax_ids_per_read:
                tax_ids_per_read[read_name] = set()
            tax_ids_per_read[read_name].add(tax_id)
    return tax_ids_per_read


def add_rank_count(read_name, count_per_rank, tax_ids, tax_id_to_rank, tax_id_to_parent):
    if len(tax_ids) == 0:
        return
    tax_ids_str = ','.join(str(i) for i in tax_ids)
    print('{}\t{}'.format(read_name, tax_ids_str), file=sys.stderr, end='\t')
    if len(tax_ids) == 1:
        (tax_id,) = tax_ids
    else:
        tax_ids.discard(0)
        tax_id = find_lca(tax_ids, tax_id_to_parent)
    rank = tax_id_to_rank[tax_id]
    print('{}\t{}'.format(tax_id, rank), file=sys.stderr)
    count_per_rank[rank] += 1
    return tax_id


def find_lca(tax_ids, tax_id_to_parent):
    """
    This function takes a set of tax IDs and (using the tree structure in tax_id_to_parent) returns
    the tax ID of their lowest common ancestor.
    """
    # Find the set of ancestor taxa common to all of the input tax IDs.
    common_taxa = set()
    for tax_id in tax_ids:
        ancestors = get_all_ancestors(tax_id, tax_id_to_parent)
        if not common_taxa:
            common_taxa = set(ancestors)
        else:
            common_taxa &= set(ancestors)

    # Return the first ancestor that's in the common set.
    one_tax_id = next(iter(tax_ids))  # just get one of the tax IDs (doesn't matter which)
    for ancestor in get_all_ancestors(one_tax_id, tax_id_to_parent):
        if ancestor in common_taxa:
            return ancestor

    # The code should never get here! I.e. at least one of the tax ID's ancestors should be in the
    # common set.
    assert False


def get_all_ancestors(tax_id, tax_id_to_parent):
    """
    Given a tax ID, this function returns a list of all of its ancestors (including the tax ID
    itself). The list is ordered with the tax ID at the start and the root (tax ID 1) at the end.
    """
    ancestors = [tax_id]
    while tax_id != 1:  # loop until we hit the root
        tax_id = tax_id_to_parent[tax_id]
        ancestors.append(tax_id)
    assert ancestors[-1] == 1  # all ancestor lists should end with node 1 (the root)
    return ancestors


def print_headers(args):
    if args.header:
        # Stdout header
        header = 'file\tread_count'
        for rank in ['unclassified', 'root', 'domain', 'phylum', 'class', 'order', 'family',
                     'genus', 'species']:
            header += '\t{}_count\t{}_percent'.format(rank, rank)
        header += '\tlca_ids\talign_ids\tleaf_ids\ttotal_ids'
        print(header)

        # Stderr header
        print('\t'.join(['read_name', 'alignment_classes', 'lca_class', 'lca_rank']),
              file=sys.stderr)


    # If the user only asked for the header and nothing else, then we're done.
    if args.sam is None:
        sys.exit(0)


def print_summary(sam_filename, read_count, count_per_rank, align_ids, leaves, lca_ids):
    total = sum(count_per_rank.values())
    summary = '{}\t{}'.format(sam_filename, read_count)
    total_count = 0
    for rank in ['unclassified', 'root', 'domain', 'phylum', 'class', 'order', 'family', 'genus',
                 'species']:
        count = count_per_rank[rank]
        total_count += count
        percent = 100 * count / total
        summary += '\t{}\t{:.4f}'.format(count, percent)
    assert read_count == total_count  # sanity check
    summary += '\t{}'.format(len(lca_ids))
    summary += '\t{}'.format(len(align_ids))
    summary += '\t{}'.format(len(leaves))
    total_ids = align_ids | lca_ids
    summary += '\t{}'.format(len(total_ids))
    print(summary)


def get_compression_type(filename):
    """
    Attempts to guess the compression (if any) on a file using the first few bytes.
    http://stackoverflow.com/questions/13044562
    """
    magic_dict = {'gz': (b'\x1f', b'\x8b', b'\x08'),
                  'bz2': (b'\x42', b'\x5a', b'\x68'),
                  'zip': (b'\x50', b'\x4b', b'\x03', b'\x04')}
    max_len = max(len(x) for x in magic_dict)

    unknown_file = open(filename, 'rb')
    file_start = unknown_file.read(max_len)
    unknown_file.close()
    compression_type = 'plain'
    for file_type, magic_bytes in magic_dict.items():
        if file_start.startswith(magic_bytes):
            compression_type = file_type
    if compression_type == 'bz2':
        sys.exit('Error: cannot use bzip2 format - use gzip instead')
    if compression_type == 'zip':
        sys.exit('Error: cannot use zip format - use gzip instead')
    return compression_type


def get_open_func(filename):
    if get_compression_type(filename) == 'gz':
        return gzip.open
    else:  # plain text
        return open


def check_arguments(args):
    if not args.header and (args.sam is None or args.tree is None):
        sys.exit('Error: both --sam and --tree are required (if not using --header)')


if __name__ == '__main__':
    main()
